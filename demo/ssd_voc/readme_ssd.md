sd的一切

### 设计
**关于总体结构**
1. ssd的总体结构：vgg16 + cls_head(3x3) + bbox_head(3x3)
2. vgg16主要是基于2组3x3和3组3x3的两种模块，分别模拟5x5, 7x7的滤波核进行特征学习，同时修改vgg16增加额外的几层3x3来实现下采样获取多尺度特征层。
   最终提取到6层多尺度特征图()
   同时在vgg16基础骨架上增加了一层l2_norm主要用来处理第0层特征层的输出，因为第0层输出的激活值相比其他层大，为了让多个特征层的激活值在统一水平范围，
   就只在第0层增加一层归一化l2_norm，他的操作就是
3. 分类、回归头很简单，只用3x3进行层数调整，然后就是permute/reshape/concate即获得各个头的特征输出(b,-1,2),(b,-1,4),(b,-1,10)


**关于如何定义训练target**
1. cls_score的target: 每个anchor的类别概率的预测是典型分类问题，

2. bbox_pred的target: bbox的4点位置坐标的预测是典型回归问题，

3. landmark的target: 关键点的5点坐标的预测是典型回归问题，


**关于anchor尺寸和生成机制**
1. ssd作为通用性目标检测算法


**关于输入图片尺寸**
1. 训练的时候，把图片强制到300*300，主要是为了batch图片能够叠加进行训练。而获取300*300的方式是：
    - 直接resize到300*300 
    - 这种处理图片的方式有一定的缺陷，因为图片会产生比例上的改变，这对训练样本中人脸的bbox尺寸也改变了，也就导致训练的样本跟实际的样本之间有比例上的差别。
      比如训练的车子有可能被在水平方向挤压，偏方形(图片是挤压过的300*300），而实际车子的形状则是长方形。

2. 测试的时候，由于不需要对图片进行堆叠，只是单图进行预测计算，所以理论上不需要强制图片尺寸到300*300。
    - 但SSD有个问题在于前向计算的多尺度特征图的最后一层默认下采样到(b,c,1,1)，也就是基于300*300计算得到w,h=1, 下采样比例是1/300，这个下采样比例太高，所以如果
      测试的图片小于300，在ssd中就会导致计算最后一层特征层时报错，因为w,h小于1了。因此测试的时候一般是缩放到300*300(不能是300以内)。


**缺陷**
1. 对小物体的检测效果不太好：根源是多级特征没有融合，高级语义特征无法被低层特征使用。改进方式是增加特征融合模块，比如FPN+SSH

### 调试




